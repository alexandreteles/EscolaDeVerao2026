{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treinamento com Unsloth para classificação de toxicidade (TOLD-BR)\n",
        "\n",
        "Notebook para fine-tuning supervisionado (SFT) com LoRA/QLoRA usando o dataset `JAugusto97/told-br` do Hugging Face."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Instalação de dependências (se necessário)\n",
        "\n",
        "> Descomente a célula abaixo se estiver em ambiente limpo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install -U unsloth datasets trl transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Configurações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"dataset_name\": \"JAugusto97/told-br\",\n",
        "    \"dataset_config\": None,\n",
        "    \"model_name\": \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"output_dir\": \"outputs/toldbr-unsloth\",\n",
        "    \"max_seq_length\": 1024,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"grad_accum\": 4,\n",
        "    \"epochs\": 2,\n",
        "    \"learning_rate\": 2e-4,\n",
        "    \"warmup_ratio\": 0.05,\n",
        "    \"lora_r\": 16,\n",
        "    \"lora_alpha\": 16,\n",
        "    \"lora_dropout\": 0.0,\n",
        "    \"seed\": 42,\n",
        "    \"test_size\": 0.1,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Funções auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE = \"\"\"### Instrução:\n",
        "Classifique a mensagem abaixo como TOXICA ou NAO_TOXICA.\n\n",
        "### Mensagem:\n",
        "{texto}\n\n",
        "### Resposta:\n",
        "{rotulo}\"\"\"\n\n",
        "TEXT_CANDIDATES = (\"text\", \"texto\", \"tweet\", \"sentence\", \"comment\", \"content\")\n",
        "LABEL_CANDIDATES = (\"label\", \"toxic\", \"toxicity\", \"classe\", \"class\", \"target\")\n\n",
        "def find_column(columns, candidates, kind):\n",
        "    for candidate in candidates:\n",
        "        if candidate in columns:\n",
        "            return candidate\n",
        "\n",
        "    lowered = {column.lower(): column for column in columns}\n",
        "    for candidate in candidates:\n",
        "        if candidate in lowered:\n",
        "            return lowered[candidate]\n",
        "\n",
        "    raise ValueError(\n",
        "        f\"Não foi possível identificar a coluna de {kind}. Colunas disponíveis: {list(columns)}\"\n",
        "    )\n\n",
        "def normalize_label(value):\n",
        "    if isinstance(value, bool):\n",
        "        return \"TOXICA\" if value else \"NAO_TOXICA\"\n",
        "\n",
        "    if isinstance(value, int):\n",
        "        return \"TOXICA\" if value == 1 else \"NAO_TOXICA\"\n",
        "\n",
        "    text_value = str(value).strip().lower()\n",
        "    toxic_aliases = {\"1\", \"toxic\", \"toxica\", \"tóxica\", \"hate\", \"abusive\"}\n",
        "    return \"TOXICA\" if text_value in toxic_aliases else \"NAO_TOXICA\"\n\n",
        "def format_example(example, text_column, label_column):\n",
        "    texto = str(example[text_column]).strip()\n",
        "    rotulo = normalize_label(example[label_column])\n",
        "    return {\"text\": PROMPT_TEMPLATE.format(texto=texto, rotulo=rotulo)}\n\n",
        "def ensure_train_eval(dataset, test_size, seed):\n",
        "    if isinstance(dataset, DatasetDict):\n",
        "        if \"train\" in dataset and \"validation\" in dataset:\n",
        "            return DatasetDict(train=dataset[\"train\"], validation=dataset[\"validation\"])\n",
        "        if \"train\" in dataset and \"test\" in dataset:\n",
        "            return DatasetDict(train=dataset[\"train\"], validation=dataset[\"test\"])\n",
        "        if \"train\" in dataset:\n",
        "            split = dataset[\"train\"].train_test_split(test_size=test_size, seed=seed)\n",
        "            return DatasetDict(train=split[\"train\"], validation=split[\"test\"])\n",
        "\n",
        "    if isinstance(dataset, Dataset):\n",
        "        split = dataset.train_test_split(test_size=test_size, seed=seed)\n",
        "        return DatasetDict(train=split[\"train\"], validation=split[\"test\"])\n",
        "\n",
        "    raise ValueError(\"Não foi possível construir splits de treino/validação para o dataset informado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Carregar e preparar o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dataset = load_dataset(config[\"dataset_name\"], config[\"dataset_config\"])\n",
        "dataset = ensure_train_eval(raw_dataset, test_size=config[\"test_size\"], seed=config[\"seed\"])\n\n",
        "text_column = find_column(dataset[\"train\"].column_names, TEXT_CANDIDATES, \"texto\")\n",
        "label_column = find_column(dataset[\"train\"].column_names, LABEL_CANDIDATES, \"rótulo\")\n\n",
        "train_dataset = dataset[\"train\"].map(\n",
        "    format_example,\n",
        "    fn_kwargs={\"text_column\": text_column, \"label_column\": label_column},\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    desc=\"Formatando treino\",\n",
        ")\n\n",
        "eval_dataset = dataset[\"validation\"].map(\n",
        "    format_example,\n",
        "    fn_kwargs={\"text_column\": text_column, \"label_column\": label_column},\n",
        "    remove_columns=dataset[\"validation\"].column_names,\n",
        "    desc=\"Formatando validação\",\n",
        ")\n\n",
        "print(train_dataset[0][\"text\"][:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Carregar modelo e aplicar LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=config[\"model_name\"],\n",
        "    max_seq_length=config[\"max_seq_length\"],\n",
        "    load_in_4bit=True,\n",
        ")\n\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=config[\"lora_r\"],\n",
        "    lora_alpha=config[\"lora_alpha\"],\n",
        "    lora_dropout=config[\"lora_dropout\"],\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=config[\"seed\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Configurar trainer e treinar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = SFTConfig(\n",
        "    output_dir=config[\"output_dir\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
        "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
        "    gradient_accumulation_steps=config[\"grad_accum\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    num_train_epochs=config[\"epochs\"],\n",
        "    warmup_ratio=config[\"warmup_ratio\"],\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    logging_steps=10,\n",
        "    seed=config[\"seed\"],\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    optim=\"adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=\"none\",\n",
        ")\n\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=training_args,\n",
        "    max_seq_length=config[\"max_seq_length\"],\n",
        "    packing=False,\n",
        ")\n\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Salvar artefatos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(config[\"output_dir\"])\n",
        "tokenizer.save_pretrained(config[\"output_dir\"])\n",
        "print(f\"Treinamento concluído. Artefatos em: {config['output_dir']}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}